---
title: "A8a-ts_analysis_val"
author: "Jasper"
format: html
editor: visual
---

Script that performs the entire time series analysis (A2, A3, A4, A5, A6, A7) for the validation points. 

```{r}
library(tidyverse)
library(sf)
library(fable)
library(fabletools)
library(feasts)
library(data.table)
library(terra)
library(lubridate)
library(tsibble)
library(ggplot2)
library(scales)
library(zoo)
library(caret)
library(lme4)
library(ranger)
library(ROCit)
library(plotly)
library(viridis)
library(TSS.RESTREND)
library(scales)
```

# Import and pre-process validation data

```{r}
# Add column validation data
val_pnts <- st_read('data/validation_points.GeoJSON')
#val_pnts <- val_pnts %>% 
#  arrange(country, regreened) %>% 
#  mutate(plotID = seq(1,nrow(val)))

# Write validation point data as geojson and csv
st_write(obj=val_pnts, dsn='data/validation_points.GeoJSON', driver='GeoJSON')
st_write(obj=val_pnts, dsn='data/validation_points.csv', driver='CSV')
#st_write(obj=val_pnts[val_pnts$regreened==0,], dsn='data/validation_points_0.GeoJSON', driver='GeoJSON')
```

# Extract satellite information
Extract the landsat 8 and GPM satellite information using the GEE extract script (A2)


# Create reflectance dataframe for validation points
Function for cloud filtering

```{r}
cloud_landsat <- function(x){
  bits <- as.numeric(intToBits(x))[1:16]
  if(bits[7] == 1 && bits[5] == 0 && bits[3] == 0){
    return(0)
  }
  else(return(1))
}
```

Convert to reflectance and add dates

```{r}
refl_val <- fread('output/gee/Val_refl_l8.csv', select =c('date', 'SR_B4', 'SR_B5','QA_PIXEL','plotID'))  

refl_val$date <- as.Date(refl_val$date, tryFormats = "%d/%m/%Y")
  
# Scale DN values to reflectance values
scale_fac <- 0.0000275
offset <- -0.2
refl_val[,c('SR_B4', 'SR_B5')] <- (refl_val[,c('SR_B4', 'SR_B5')] * scale_fac) + offset

# Remove negative reflectance
refl_val <- refl_val[refl_val$SR_B4 >= 0,]
refl_val <- refl_val[refl_val$SR_B5 >= 0,]
  
# Remove clouds
refl_val$clouds <- 0
refl_val$clouds <- lapply(refl_val$QA_PIXEL, cloud_landsat) # Apply function to all pixels 
refl_val <- refl_val[refl_val$clouds==0,] # Filter out pixels with clouds

# Compute some VIs
refl_val$ndvi <- (refl_val$SR_B5 - refl_val$SR_B4) / (refl_val$SR_B5 + refl_val$SR_B4)
  
# Take average per validation point and date
#(This is to remove duplicates with the same date and plotID as a result of overlapping images and a single point falling in two images on the same date)
refl_aggr_val <- refl_val[,.(ndvi=mean(ndvi,na.rm=T)), by=list(plotID, date)]

# Add yearmon
refl_aggr_val$yearmon <- as.Date(ISOdate(year(refl_aggr_val$date), month(refl_aggr_val$date), 15))
```


# Extract the GPM at validation points
Import

```{r}
# gpm
gpm <- rast('output/gee/gpm/Val_GPM_stack.tif')

# convert validation points to terra:vector
val_pnts <- vect(val_pnts)
```

Set time series parameters

```{r}
# Set start/end
start_ts <- as.Date('2012-9-01')
end_ts <- as.Date('2023-04-15')

# Determine number of months in time series period
months_dif <- (year(end_ts) - year(start_ts)) * 12 + (month(end_ts) - month(start_ts))
months_ts <- seq(ymd(start_ts), by = "month", length.out=months_dif)
```

Extract GPM at validation points and assign date + plotID

```{r}
# Assign dates to gpm_stack layers
names(gpm) <- months_ts
  
#### Extract values for each layer
gpm_val <- data.table(extract(gpm, val_pnts, cells=F))
gpm_val <- gpm_val[,-c('ID')] # remove ID column
rownames(gpm_val) <- val_pnts$plotID

# Transpose df
gpm_ts <- cbind(row = as.integer(rownames(gpm_val)), stack(gpm_val))
  
# Clean df
names(gpm_ts) <- c('plotID', 'prcp_month', 'date')
gpm_ts$yearmon <- as.Date(ISOdate(year(gpm_ts$date), month(gpm_ts$date), 15))

# Concert val_pnts back to sf object
val_pnts <- st_as_sf(val_pnts)
```


# Add precipitation to reflectance ts
```{r}
# Convert val_pnts to datatable 
val_pnts_dt <- data.table(val_pnts)

# Merge reflectance ts with precipitation data
val_ts <- merge(refl_aggr_val, gpm_ts[,c('plotID', 'yearmon','prcp_month')],
               by=c('plotID', 'yearmon'), all.y=T)

# Write complete validation time series
fwrite(val_ts, 'output/time_series/Val_l8_ts.csv')
val_ts <- fread('output/time_series/Val_l8_ts.csv')
```


# Vegetation modeling
Cut off dates outside period of interest
```{r}
# Filter out time stamps before the observation
#val_ts <- val_ts[val_ts$yearmon > as.Date('2013-01-01') & val_ts$yearmon < as.Date('2022-11-01')]
```


Create tsibble for analysis

```{r}
# Creates tsibble with lagged precipitation and interpolate the missing ndvi values
val_ts_pnt <- val_ts %>% 
  group_by(plotID, yearmon) %>% 
  summarize(ndvi=mean(ndvi, na.rm=T),
            prcp=mean(prcp_month)) %>% 
  # Add lagged precipitation variables
  mutate(prcp_lag1=data.table::shift(prcp, n=1, type='lag'),
         prcp_lag2=data.table::shift(prcp, n=2, type='lag')) %>% 
  # Check if plot ts is all NAs and exclude
  mutate(entire_na = length(which(!is.na(ndvi))) == 0) %>% 
  filter(!entire_na) %>% 
  # Exclude NAs when at beginning or end of time series
  slice(min(which(!is.na(ndvi))):max(which(!is.na(ndvi)))) %>% 
  # Remove the entire.na column
  select(!entire_na) %>% 
  # Interpolate NDVI values
  mutate(yearmonth=yearmonth(as.character(yearmon)),
         ndvi_int=na.approx(ndvi)) %>% 
  # Convert to tsibble
  as_tsibble(key=plotID, index=yearmonth) %>% 
  # Filter out time stamps before the observation
  filter(yearmon > as.Date('2013-01-01') & yearmon < as.Date('2023-01-01'))

fwrite(val_ts_pnt, 'output/time_series/Val_ts_pnt.csv')
val_ts_pnt <- read_csv('output/time_series/Val_ts_pnt.csv')

# Convert to tsibble after import
val_ts_pnt <- val_ts_pnt %>%  
  mutate(yearmonth=yearmonth(as.character(yearmon))) %>% 
  # Convert to tsibble
  as_tsibble(key=plotID, index=yearmonth)

# Create reference and validation sets
val_ref_pnt <- val_ts_pnt %>% filter(year(yearmonth) < 2017)
val_prd_pnt <- val_ts_pnt %>% filter(year(yearmonth) >= 2017)
```


Train ARIMA models and predict

```{r}
# Train ARIMA models
val_armax_pnt <- val_ref_pnt %>% 
  model(ARIMA(ndvi_int ~ prcp + prcp_lag1 + prcp_lag2 + pdq(d=0) + PDQ(D=0), stepwise = T, ic='aicc'))

# Forecast ndvi based on models and precipitation
val_fc_pnt <- fabletools::forecast(val_armax_pnt, new_data = val_prd_pnt[,c('yearmonth', 'prcp', 'prcp_lag1', 'prcp_lag2', 'plotID')])

# Extract 95% confidence levels
val_pnt_ci <- val_fc_pnt$ndvi_int %>% 
  hilo(80) 
val_fc_pnt <- val_fc_pnt %>% 
  mutate(upper = val_pnt_ci$upper,
         lower = val_pnt_ci$lower)

# Save the ARIMA models and forecast
save(val_fc_pnt, file = 'output/models/Val_l8_fc_pnt.RDS')
save(val_armax_pnt, file = 'output/models/Val_l8_armax_pnt.RDS')
load(file = 'output/models/Val_l8_fc_pnt.RDS')
load(file = 'output/models/Val_l8_armax_pnt.RDS')
```



# Interpret vegetation modeling
Prepare data
```{r}
# Select relevant rows and add yearmon column
val_fc_pnt_dt <- data.table(val_fc_pnt[,c('.mean', 'yearmonth', 'plotID', 'upper', 'lower')])
names(val_fc_pnt_dt)[names(val_fc_pnt_dt) == '.mean'] <- 'pred_test'
val_fc_pnt_dt$yearmon <- as.Date(ISOdate(year(val_fc_pnt_dt$yearmonth), month(val_fc_pnt_dt$yearmonth), 15))

# Merge actual ndvi with the predicted ndvi
val_fc_ts <- merge(val_ts_pnt, val_fc_pnt_dt[,-c('yearmonth')], by=c('yearmon', 'plotID'), all.x=T)
val_fc_ts$yearmonth <- yearmonth(val_fc_ts$yearmon)

# Merge actual ndvi with predicted reference ndvi
val_fc_ts <- merge(val_fc_ts, residuals(val_armax_pnt)[c('plotID', 'yearmonth', '.resid')], 
                   by=c('yearmonth', 'plotID'), all.x=T)

# Compute training prediction
val_fc_ts$pred_train <- val_fc_ts$ndvi_int + val_fc_ts$.resid

# Combine test and training prediction into one and convert to tsibble
val_fc_ts <- val_fc_ts %>% 
  tsibble(key=plotID, index=yearmonth) %>% 
  mutate(ndvi_pred = if_else(is.na(pred_test), pred_train, pred_test))

# Add the aridity index values to the validation plots
ai <- rast('../../data/rasters/Aridity_index_regreening.tif')
val_pnts <- terra::extract(ai, val_pnts, ID = FALSE, bind = TRUE) %>% st_as_sf() %>% rename(aridity_index = b1)  %>% mutate(aridity_index = aridity_index*0.0001)

# Add validation data to time series
val_fc_ts <- val_fc_ts %>% 
  right_join(val_pnts[,c('plotID', 'regreened', 'aridity_index')], by='plotID') %>% 
  # For caret randomforest, regreened variable cannot start with a number
  mutate(regreened = if_else(regreened == 1, 'yes', 'no'))
```

Compute plot-specific MAEp and other statistics 
```{r}
val_mae <- val_fc_ts %>% 
  mutate(test_res = ndvi_int - upper,
         test_res_0 = if_else(ndvi_int > upper, ndvi_int - upper, 0),
         pred_resid = pred_test - ndvi_int,
         training = if_else(!is.na(pred_train), 1, 0)) %>% 
  tibble() %>% 
  group_by(plotID) %>% 
  summarise(regreened = first(regreened),
            plotID = first(plotID),
            aridity_index = first(aridity_index),
            ndvi=mean(ndvi_int),
            sd=sd(ndvi_int),
            n = n(),
            n_training = sum(training),
            mae = sum(test_res, na.rm=T) / (n - n_training),
            mae_0 = sum(test_res_0, na.rm=T) / (n - n_training) * 100,
            maep = sum((test_res/ndvi_int)*100, na.rm=T) / (n - n_training),
            rmse_test = sum(sqrt(pred_resid^2), na.rm=T) / (n - n_training),
            rmse_train = sum(sqrt(.resid^2), na.rm=T) / n_training) %>% 
  mutate(Ecosystem = if_else(aridity_index < 0.2, 'Arid', NA),
        Ecosystem = if_else(aridity_index >= 0.2 & aridity_index < 0.5, 'Semi-Arid', Ecosystem),
        Ecosystem = if_else(aridity_index > 0.5, 'Dry sub-humid', Ecosystem)) %>%
  right_join(val_pnts[,c('plotID', 'country')], by='plotID') %>% 
  group_by(Ecosystem)

#st_write(st_as_sf(val_mae, sf_column_name = "geometry"), 'output/plot_data/all_countries/val_mae.GeoJSON')
write_csv(val_mae, 'output/plot_data/all_countries/val_mae.csv')
val_mae <- read_csv('output/plot_data/all_countries/val_mae.csv')
```


Perform RESTREND analysis
```{r}
# RESTREND
val_mae <- read_csv('output/plot_data/all_countries/val_mae.csv')
val_ts_pnt <- read_csv('output/time_series/Val_ts_pnt.csv')
val_ts_pnt <- val_ts_pnt %>%  
  mutate(yearmonth=yearmonth(as.character(yearmon))) %>% 
  as_tsibble(key=plotID, index=yearmonth)

val_max_pnt <- val_ts_pnt %>% 
  tibble() %>% 
  mutate(Year = year(yearmonth)) %>% 
  group_by(Year, plotID) %>% 
  summarise(ndvi_max = max(ndvi, na.rm=TRUE),
            prcp_sum = sum(prcp, na.rm=TRUE)) %>% 
  filter(Year > 2015 & Year < 2023) %>% 
  right_join(val_mae[,c('plotID', 'country','regreened','Ecosystem')], by='plotID')


restrend_df <- data.frame()
for (i in unique(val_max_pnt$plotID)){
  print(i)

  plot_df <- val_max_pnt[val_max_pnt$plotID==i,] 

  plot_ts <- ts(plot_df[,c("ndvi_max", "prcp_sum")], start = min(plot_df$Year), end = max(plot_df$Year), frequency = 1)

  restrend_output <- RESTREND(plot_ts[,'ndvi_max'], plot_ts[,'prcp_sum'], seq(start(plot_ts)[1], end(plot_ts)[1]), sig = 1, retnonsig=TRUE)

  restrend_row_coef <- data.frame(restrend_output$ols.summary$OLS.table)[2:3,]
  restrend_row_coef$fit <- row.names(restrend_row_coef)
  restrend_row_coef$plotID <- i
  restrend_row_coef$country <- val_max_pnt$country[val_max_pnt$plotID==i][1]
  restrend_row_coef$regreened <- val_max_pnt$regreened[val_max_pnt$plotID==i][1]
  restrend_row_coef$Ecosystem <- val_max_pnt$Ecosystem[val_max_pnt$plotID==i][1]

  restrend_df <- rbind(restrend_df, restrend_row_coef)
}
restrend_df <- restrend_df[restrend_df$fit =='RESTREND.fit',]

write_csv(restrend_df, 'output/plot_data/all_countries/val_restrend.csv')
```


Find accuracy MAEp and RESTREND
```{r}
##### Test accuracies of various MAEp thresholds
interval <- seq(0.5, 2, by = 0.1)

for (i in 1){
  binary <- val_mae[val_mae$Ecosystem == 'Dry sub-humid',] %>% 
    mutate(bin_class = if_else(mae_0 <= i, 'no', 'yes'))
  
  cm <- confusionMatrix(factor(binary$bin_class), 
                factor(binary$regreened), positive='yes', mode='everything')
  print(paste('The mean absolute error threshold is',i))
  print(cm)
}

###### Test accuracies of various RESTREND slope thresholds
interval <- seq(0.001, 0.02, by = 0.001)

for (i in 0.01){
  binary <- restrend_df[restrend_df$country =='Ethiopia',] %>% 
    mutate(bin_class = if_else(slope <= i, 'no', 'yes'))
  
  cm <- confusionMatrix(factor(binary$bin_class), 
                factor(binary$regreened), positive='yes', mode='everything')
  print(paste('The mean absolute error threshold is',i))
  print(cm)
}
```